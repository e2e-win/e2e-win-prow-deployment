log_level: debug

sinker:
  resync_period: 3m
  max_prowjob_age: 100h
  max_pod_age: 10h

presets:
# credential presets
- labels:
    preset-service-account: "true"
  env:
  - name: GOOGLE_APPLICATION_CREDENTIALS
    value: /etc/service-account/service-account.json
  volumes:
  - name: service
    secret:
      secretName: service-account
  volumeMounts:
  - name: service
    mountPath: /etc/service-account
    readOnly: true
- labels:
    preset-azure-creds: "true"
  env:
  - name: AZURE_CREDENTIALS
    value: /etc/azure-cred/credentials
  volumes:
  - name: azure-cred
    secret:
      secretName: azure-cred
  volumeMounts:
  - name: azure-cred
    mountPath: /etc/azure-cred
    readOnly: true
- labels:
    preset-azure-ssh: "true"
  env:
  - name: AZURE_SSH_PUBLIC_KEY_FILE
    value: /etc/azure-ssh/azure-ssh.pub
  - name: CLOUD_CONFIG
    value: random
  - name: AZ_STORAGE_CONTAINER_NAME
    value: mystoragecontainer
  - name: REGISTRY
    value: atuvenie
  - name: WIN_BUILD
    value: https://raw.githubusercontent.com/adelina-t/acs-engine/change_gen_script_for_e2e/scripts/build-windows-k8s.sh
  volumes:
  - name: azure-ssh
    secret:
      secretName: azure-ssh
      defaultMode: 256
  volumeMounts:
  - name: azure-ssh
    mountPath: /etc/azure-ssh
    readOnly: true
- labels:
    preset-repo-list: "true"
  env:
  - name: KUBE_TEST_REPO_LIST
    value: /etc/repo-list/repo-list
  volumes:
  - name: repo-list
    secret:
      secretName: repo-list
  volumeMounts:
  - name: repo-list
    mountPath: /etc/repo-list
    readOnly: true
- labels:
    preset-azure-storage: "true"
  env:
  - name: AZ_STORAGE_KEY
    valueFrom:
      secretKeyRef:
        name: azure-storage
        key: az_storage_key
  - name: AZ_STORAGE_ACCOUNT
    valueFrom:
      secretKeyRef:
        name: azure-storage
        key: az_storage_account
- labels:
    preset-acs-creds: "true"
  env:
  - name: ACS_USER
    valueFrom:
      secretKeyRef:
        name: acs-creds
        key: username
  - name: ACS_PASSWORD
    valueFrom:
      secretKeyRef:
        name: acs-creds
        key: password
- labels:
    preset-kube-config: "true"
  volumes:
  - name: kube-conf
    secret:
      secretName: kube-conf
  volumeMounts:
  - name: kube-conf
    mountPath: /root/.kube/
    readOnly: true

presubmits:
  e2e-win/test-infra:
  - name: pull-build-kubekins
    agent: kubernetes
    context: pull-build-kubekins
    always_run: false
    rerun_command: "/test pull-build-kubekins"
    trigger: "(?m)^/test( all| pull-build-kubekins),?(\\s+|$)" 
    labels:
      preset-service-account: "true"
    spec:
      containers:
      - image: gcr.io/win-e2e-test/build_kubekins:latest
        env:
        - name: DOCKER_IN_DOCKER_ENABLED
          value: "true"
           # docker-in-docker needs privileged mode
        volumeMounts:
        - name: docker-graph
          mountPath: /docker-graph
        securityContext:
          privileged: true
      volumes:
        - name: docker-graph
          emptyDir: {}
  
  e2e-win/kubernetes:
  - name: ci-kubernetes-build-stable1
    agent: kubernetes
    context: ci-kubernetes-build-stable1
    always_run: false
    rerun_command: "/test ci-kubernetes-build-stable1"
    trigger: "(?m)^/test( all| ci-kubernetes-build-stable1),?(\\s+|$)"
    labels:
      preset-service-account: "true"
    spec:
      containers:
      - image: atuvenie/kubekins-e2e:1.0-master
        args:
        - "--repo=k8s.io/kubernetes=release-1.10"
        - "--repo=k8s.io/release"
        - "--root=/go/src"
        - "--timeout=120"
        - "--"
        - "--allow-dup"
        - "--extra-publish-file=k8s-stable1"
        - "--hyperkube"
        - "--registry=atuvenie"
        env:
        - name: DOCKER_IN_DOCKER_ENABLED
          value: "true"
          # docker-in-docker needs privileged mode
        securityContext:
          privileged: true
        volumeMounts:
        - name: docker-graph
          mountPath: /docker-graph
#        resources:
#          requests:
#            cpu: 2
#            memory: "3Gi"
      volumes:
      - name: docker-graph
        emptyDir: {}
          
  - name: pull-kubernetes-e2e-win
    agent: kubernetes
    context: pull-kubernetes-e2e-win
    always_run: false
    rerun_command: "/test pull-kubernetes-e2e-win"
    trigger: "(?m)^/test( all| pull-kubernetes-e2e-win),?(\\s+|$)"
    skip_branches:
    - release-1.10 # different bazel version
    - release-1.9 # need to cherry pick back https://github.com/kubernetes/kubernetes/pull/59251, possibly others
    - release-1.8 # different set of targets
    labels:
      preset-service-account: "true"
      preset-azure-creds: "true"
      preset-azure-ssh: "true"
    spec:
      containers:
      - image: atuvenie/kubekins-e2e:1.0-master
        args:
        - "--job=$(JOB_NAME)"
        - "--repo=github.com/e2e-win/$(REPO_NAME)=$(PULL_REFS)"
        - "--root=/go/src"
        - "--service-account=/etc/service-account/service-account.json"
        - "--upload=gs://win-e2e-test/pr-logs"
        - "--timeout=300"
        - "--scenario=kubernetes_e2e"
        - "--" # end bootstrap args, scenario args below
        - "--deployment=acsengine"
        - "--provider=azure"
        - "--test=true"
        - "--up=true"
        - "--down=false"
        - "--build=bazel"
        - "--ginkgo-parallel=8"
        - "--acsengine-admin-password=Passw0rdAdmin"
        - "--acsengine-admin-username=$azureuser"
        - "--acsengine-download-url=https://github.com/Azure/acs-engine/releases/download/v0.18.9/acs-engine-v0.18.9-linux-amd64.tar.gz"
        - "--acsengine-orchestratorRelease=1.11"
        - "--acsengine-creds=$AZURE_CREDENTIALS"
        - "--acsengine-public-key=$AZURE_SSH_PUBLIC_KEY_FILE"
        - "--acsengine-winZipBuildScript=$WIN_BUILD"
        - "--acsengine-location=eastus"
        - "--test_args=--ginkgo.dryRun=false --ginkgo.noColor --ginkgo.focus=\\[Conformance\\]|\\[NodeConformance\\] --ginkgo.skip=\\[Serial\\]|\\[k8s.io\\].KubeletManagedEtcHosts.should.test.kubelet.managed./etc/hosts.file.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].PrivilegedPod.\\[NodeConformance\\].should.enable.privileged.commands|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.mappings.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.as.non-root.with.defaultMode.and.fsGroup.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.Mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.as.non-root.with.defaultMode.and.fsGroup.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.Mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.set.DefaultMode.on.files.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.set.mode.on.item.file.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Downward.API.volume.should.set.DefaultMode.on.files.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Downward.API.volume.should.set.mode.on.item.file.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0644,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0644,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0666,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0666,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0777,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0777,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0644,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0644,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0666,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0666,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0777,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0777,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.volume.on.default.medium.should.have.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.volume.on.tmpfs.should.have.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].HostPath.should.give.a.volume.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.configmap.pod.with.mountPath.of.existing.file.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.projected.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.secret.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.configmap.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.downward.pod.\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.poststart.exec.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.poststart.http.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.prestop.exec.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.prestop.http.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.from.private.registry.with.secret.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.image.from.docker.hub.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.image.from.gcr.io.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.from.private.registry.without.secret.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.image.from.invalid.registry.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.non-existing.image.from.gcr.io.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.as.empty.when.pod.succeeds.and.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.from.file.when.pod.succeeds.and.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.from.log.output.if.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.if.TerminationMessagePath.is.set.as.non-root.user.and.at.a.non-default.path.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.if.TerminationMessagePath.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.run.with.the.expected.status.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.container.with.runAsUser.should.run.the.container.with.uid.0.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.container.with.runAsUser.should.run.the.container.with.uid.65534.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.privileged.should.run.the.container.as.unprivileged.when.false.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.readOnlyRootFilesystem.should.run.the.container.with.readonly.rootfs.when.readOnlyRootFilesystem=true.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.readOnlyRootFilesystem.should.run.the.container.with.writable.rootfs.when.readOnlyRootFilesystem=false.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.allow.privilege.escalation.when.not.explicitly.set.and.uid.!=.0.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.allow.privilege.escalation.when.true.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.not.allow.privilege.escalation.when.false.\\[NodeConformance\\]"
        env:
        - name: DOCKER_IN_DOCKER_ENABLED
          value: "true"
          # docker-in-docker needs privileged mode
        volumeMounts:
        - name: docker-graph
          mountPath: /docker-graph
        securityContext:
          privileged: true
      volumes:
        - name: docker-graph
          emptyDir: {}

  - name: test-acs-engine-stable
    agent: kubernetes
    context: test-acs-engine-stable
    always_run: false
    rerun_command: "/test test-acs-engine-stable"
    trigger: "(?m)^/test( all| test-acs-engine-stable),?(\\s+|$)"
    labels:
      preset-service-account: "true"
      preset-azure-creds: "true"
      preset-azure-ssh: "true"
    spec:
      containers:
        - image: gcr.io/win-e2e-test/build_acs_engine
      
  Azure/acs-engine:
  - name: pull-acs-engine
    agent: kubernetes
    context: pull-acs-engine
    always_run: false
    max_concurrency: 5
    rerun_command: "/test pull-acs-engine"
    trigger: "/test pull-acs-engine"
    labels:
      preset-service-account: "true"
      preset-azure-creds: "true"
      preset-azure-ssh: "true"
      preset-repo-list: "true"
    spec:
      containers:
        - image: gcr.io/win-e2e-test/build_acs_engine
          env:
          - name: GINKGO_PARALLEL
            value: "8"
          - name: AGENT_NODES
            value: "3"
#    run_after_success:
#    - name: build-acs
#      agent: kubernetes
#      context: build-acs
#      labels:
#        preset-service-account: "true"
#        preset-azure-creds: "true"
#        preset-azure-ssh: "true"
#        preset-azure-storage: "true"
#      spec:
#        containers:
#          - image: gcr.io/win-e2e-test/build_acs

  # - name: pull-acs-engine-linux
  #   agent: kubernetes
  #   context: pull-acs-engine
  #   always_run: true
  #   max_concurrency: 5
  #   rerun_command: "/test pull-acs-engine-linux"
  #   trigger: "/test pull-acs-engine-linux"
  #   labels:
  #     preset-service-account: "true"
  #     preset-azure-creds: "true"
  #     preset-azure-ssh: "true"
  #     preset-azure-repo-list: "false"
  #   spec:
  #     containers:
  #       - image: gcr.io/win-e2e-test/build_acs_engine
  #         env:
  #         - name: GINKGO_PARALLEL
  #           value: "8"
  #         - name: AGENT_NODES
  #           value: "3"
  #         - name: OS_TYPE
  #           value: "Linux"

postsubmits:
  e2e-win/test-infra:
  - name: test-build-kubetest-post
    agent: kubernetes
    branches:
    - azure_provider
    - test
    labels:
      preset-service-account: "true"
      preset-azure-creds: "true"
      preset-azure-ssh: "true"
      preset-azure-storage: "true"
    spec:
     containers:
     - image: gcr.io/win-e2e-test/build_kubetest:latest

  - name: test-build-kubekins-bootstrap
    agent: kubernetes
    branches:
    - master
    labels:
      preset-service-account: "true"
    spec:
      containers:
      - image: papagalu/build_kubekins:0.1
        env:
        - name: DOCKER_IN_DOCKER_ENABLED
          value: "true"
          # docker-in-docker needs privileged mode
        volumeMounts:
        - name: docker-graph
          mountPath: /docker-graph
        securityContext:
          privileged: true
      volumes:
        - name: docker-graph
          emptyDir: {}
  
  e2e-win/e2e-win-prow-deployment:
  - name: test-build-acs-engine-test-image
    agent: kubernetes
    branches:
    - master
    - acs-job-exclusion-list
    labels:
      preset-service-account: "true"
      preset-azure-creds: "true"
      preset-azure-ssh: "true"
    spec:
      containers:
      - image: gcr.io/win-e2e-test/build_acs_e2e
        env:
        - name: DOCKER_IN_DOCKER_ENABLED
          value: "true"
          # docker-in-docker needs privileged mode
        volumeMounts:
        - name: docker-graph
          mountPath: /docker-graph
        securityContext:
          privileged: true
      volumes:
        - name: docker-graph
          emptyDir: {}

  - name: update-config
    agent: kubernetes
    branches:
    - master
    - papagalu-test
    labels:
      preset-kube-config: "true"
    spec:
      containers:
      - image: gcr.io/win-e2e-test/update-config

periodics:
- interval: 24h
  agent: kubernetes
  name: asc-engine-build-job
  labels:
    preset-azure-storage: "true"
    preset-service-account: "true"
  spec:
    containers:
    - image: gcr.io/win-e2e-test/build_acs_engine:latest

- interval: 24h
  agent: kubernetes
  name: kubetest-build-job
  labels:
    preset-azure-storage: "true"
  spec:
    containers:
    - image: gcr.io/win-e2e-test/build_kubetest:latest

- interval: 3h
  name: pull-kubernetes-e2e-win-1-12-fast
  agent: kubernetes
  context: pull-kubernetes-e2e-win-1-12-fast
  labels:
    preset-service-account: "true"
    preset-azure-creds: "true"
    preset-azure-ssh: "true"
    preset-azure-storage: "true"
    preset-repo-list: "true"
  spec:
    containers:
    - image: gcr.io/win-e2e-test/kubekins-e2e:latest-master
      args:
      - "--job=$(JOB_NAME)"
      - "--repo=github.com/e2e-win/kubernetes=master"
      - "--root=/go/src"
      - "--service-account=/etc/service-account/service-account.json"
      - "--upload=gs://win-e2e-test/pr-logs"
      - "--timeout=600"
      - "--scenario=kubernetes_e2e"
      - "--" # end bootstrap args, scenario args below
      - "--build=host-go"
      - "--deployment=acsengine"
      - "--provider=azure"
      - "--test=true"
      - "--up=true"
      - "--down=true"
      - "--ginkgo-parallel=8"
      - "--acsengine-admin-password=Passw0rdAdmin"
      - "--acsengine-admin-username=azureuser"
      - "--acsengine-resource-name=prow-${PROW_JOB_ID}"
      - "--acsengine-resourcegroup-name=${JOB_NAME}-${PROW_JOB_ID}"
      - "--acsengine-download-url=https://github.com/Azure/acs-engine/releases/download/v0.21.2/acs-engine-v0.21.2-linux-amd64.tar.gz"
      - "--acsengine-creds=$AZURE_CREDENTIALS"
      - "--acsengine-agentpoolcount=4"
      - "--acsengine-public-key=$AZURE_SSH_PUBLIC_KEY_FILE"
      - "--acsengine-winZipBuildScript=$WIN_BUILD"
      - "--acsengine-location=westus2"
      - "--acsengine-orchestratorRelease=1.12"
      - "--acsengine-win-binaries-url=https://acs-mirror.azureedge.net/wink8s/v1.12.0-beta.1-1int.zip"
      - "--acsengine-hyperkube-url=k8s.gcr.io/hyperkube-amd64:v1.12.0-beta.1"
      - "--test_args=--ginkgo.dryRun=false --ginkgo.noColor --ginkgo.focus=\\[Conformance\\]|\\[NodeConformance\\] --ginkgo.skip=\\[Serial\\]|\\[k8s.io\\].KubeletManagedEtcHosts.should.test.kubelet.managed./etc/hosts.file.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].PrivilegedPod.\\[NodeConformance\\].should.enable.privileged.commands|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.mappings.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.as.non-root.with.defaultMode.and.fsGroup.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.Mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.as.non-root.with.defaultMode.and.fsGroup.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.Mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.set.DefaultMode.on.files.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.set.mode.on.item.file.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Downward.API.volume.should.set.DefaultMode.on.files.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Downward.API.volume.should.set.mode.on.item.file.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0644,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0644,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0666,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0666,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0777,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0777,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0644,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0644,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0666,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0666,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0777,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0777,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.volume.on.default.medium.should.have.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.volume.on.tmpfs.should.have.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].HostPath.should.give.a.volume.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.configmap.pod.with.mountPath.of.existing.file.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.projected.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.secret.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.configmap.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.downward.pod.\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.poststart.exec.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.poststart.http.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.prestop.exec.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.prestop.http.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.from.private.registry.with.secret.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.image.from.docker.hub.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.image.from.gcr.io.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.from.private.registry.without.secret.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.image.from.invalid.registry.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.non-existing.image.from.gcr.io.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.as.empty.when.pod.succeeds.and.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.from.file.when.pod.succeeds.and.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.from.log.output.if.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.if.TerminationMessagePath.is.set.as.non-root.user.and.at.a.non-default.path.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.if.TerminationMessagePath.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.run.with.the.expected.status.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.container.with.runAsUser.should.run.the.container.with.uid.0.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.container.with.runAsUser.should.run.the.container.with.uid.65534.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.privileged.should.run.the.container.as.unprivileged.when.false.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.readOnlyRootFilesystem.should.run.the.container.with.readonly.rootfs.when.readOnlyRootFilesystem=true.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.readOnlyRootFilesystem.should.run.the.container.with.writable.rootfs.when.readOnlyRootFilesystem=false.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.allow.privilege.escalation.when.not.explicitly.set.and.uid.!=.0.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.allow.privilege.escalation.when.true.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.not.allow.privilege.escalation.when.false.\\[NodeConformance\\]"
      env:
      - name: DOCKER_IN_DOCKER_ENABLED
        value: "true"
        # docker-in-docker needs privileged mode
      volumeMounts:
      - name: docker-graph
        mountPath: /docker-graph
      securityContext:
        privileged: true
    volumes:
      - name: docker-graph
        emptyDir: {}

- interval: 3h
  name: pull-kubernetes-e2e-win-1-12-seq
  agent: kubernetes
  context: pull-kubernetes-e2e-win-1-12-seq
  labels:
    preset-service-account: "true"
    preset-azure-creds: "true"
    preset-azure-ssh: "true"
    preset-azure-storage: "true"
    preset-repo-list: "true"
  spec:
    containers:
    - image: gcr.io/win-e2e-test/kubekins-e2e:latest-master
      args:
      - "--job=$(JOB_NAME)"
      - "--repo=github.com/e2e-win/kubernetes=master"
      - "--root=/go/src"
      - "--service-account=/etc/service-account/service-account.json"
      - "--upload=gs://win-e2e-test/pr-logs"
      - "--timeout=600"
      - "--scenario=kubernetes_e2e"
      - "--" # end bootstrap args, scenario args below
      - "--build=host-go"
      - "--deployment=acsengine"
      - "--provider=azure"
      - "--test=true"
      - "--up=true"
      - "--down=true"
      - "--ginkgo-parallel=1"
      - "--acsengine-admin-password=Passw0rdAdmin"
      - "--acsengine-admin-username=azureuser"
      - "--acsengine-resource-name=prow-${PROW_JOB_ID}"
      - "--acsengine-resourcegroup-name=${JOB_NAME}-${PROW_JOB_ID}"
      - "--acsengine-download-url=https://github.com/Azure/acs-engine/releases/download/v0.21.2/acs-engine-v0.21.2-linux-amd64.tar.gz"
      - "--acsengine-creds=$AZURE_CREDENTIALS"
      - "--acsengine-agentpoolcount=4"
      - "--acsengine-public-key=$AZURE_SSH_PUBLIC_KEY_FILE"
      - "--acsengine-winZipBuildScript=$WIN_BUILD"
      - "--acsengine-location=westus2"
      - "--acsengine-orchestratorRelease=1.12"
      - "--acsengine-win-binaries-url=https://acs-mirror.azureedge.net/wink8s/v1.12.0-beta.1-1int.zip"
      - "--acsengine-hyperkube-url=k8s.gcr.io/hyperkube-amd64:v1.12.0-beta.1"
      - "--test_args=--ginkgo.dryRun=false --ginkgo.noColor --ginkgo.focus=\\[Conformance\\]|\\[NodeConformance\\] --ginkgo.skip=\\[Serial\\]|\\[k8s.io\\].KubeletManagedEtcHosts.should.test.kubelet.managed./etc/hosts.file.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].PrivilegedPod.\\[NodeConformance\\].should.enable.privileged.commands|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.mappings.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.as.non-root.with.defaultMode.and.fsGroup.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.Mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.as.non-root.with.defaultMode.and.fsGroup.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.Mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.set.DefaultMode.on.files.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.set.mode.on.item.file.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Downward.API.volume.should.set.DefaultMode.on.files.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Downward.API.volume.should.set.mode.on.item.file.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0644,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0644,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0666,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0666,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0777,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0777,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0644,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0644,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0666,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0666,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0777,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0777,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.volume.on.default.medium.should.have.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.volume.on.tmpfs.should.have.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].HostPath.should.give.a.volume.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.configmap.pod.with.mountPath.of.existing.file.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.projected.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.secret.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.configmap.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.downward.pod.\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.poststart.exec.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.poststart.http.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.prestop.exec.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.prestop.http.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.from.private.registry.with.secret.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.image.from.docker.hub.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.image.from.gcr.io.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.from.private.registry.without.secret.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.image.from.invalid.registry.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.non-existing.image.from.gcr.io.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.as.empty.when.pod.succeeds.and.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.from.file.when.pod.succeeds.and.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.from.log.output.if.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.if.TerminationMessagePath.is.set.as.non-root.user.and.at.a.non-default.path.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.if.TerminationMessagePath.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.run.with.the.expected.status.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.container.with.runAsUser.should.run.the.container.with.uid.0.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.container.with.runAsUser.should.run.the.container.with.uid.65534.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.privileged.should.run.the.container.as.unprivileged.when.false.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.readOnlyRootFilesystem.should.run.the.container.with.readonly.rootfs.when.readOnlyRootFilesystem=true.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.readOnlyRootFilesystem.should.run.the.container.with.writable.rootfs.when.readOnlyRootFilesystem=false.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.allow.privilege.escalation.when.not.explicitly.set.and.uid.!=.0.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.allow.privilege.escalation.when.true.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.not.allow.privilege.escalation.when.false.\\[NodeConformance\\]"
      env:
      - name: DOCKER_IN_DOCKER_ENABLED
        value: "true"
        # docker-in-docker needs privileged mode
      volumeMounts:
      - name: docker-graph
        mountPath: /docker-graph
      securityContext:
        privileged: true
    volumes:
      - name: docker-graph
        emptyDir: {}

# - interval: 3h
#   name: pull-kubernetes-e2e-win-1-12-kubenet1
#   agent: kubernetes
#   context: pull-kubernetes-e2e-win-1-12-kubenet1
#   labels:
#     preset-service-account: "true"
#     preset-azure-creds: "true"
#     preset-azure-ssh: "true"
#     preset-azure-storage: "true"
#     preset-repo-list: "true"
#   spec:
#     containers:
#     - image: gcr.io/win-e2e-test/kubekins-e2e:latest-master
#       args:
#       - "--job=$(JOB_NAME)"
#       - "--repo=github.com/e2e-win/kubernetes=master"
#       - "--root=/go/src"
#       - "--service-account=/etc/service-account/service-account.json"
#       - "--upload=gs://win-e2e-test/pr-logs"
#       - "--timeout=600"
#       - "--scenario=kubernetes_e2e"
#       - "--" # end bootstrap args, scenario args below
#       - "--build=host-go"
#       - "--deployment=acsengine"
#       - "--provider=azure"
#       - "--test=true"
#       - "--up=true"
#       - "--down=true"
#       - "--ginkgo-parallel=6"
#       - "--acsengine-admin-password=Passw0rdAdmin"
#       - "--acsengine-admin-username=azureuser"
#       - "--acsengine-resource-name=prow-${PROW_JOB_ID}"
#       - "--acsengine-resourcegroup-name=${JOB_NAME}-${PROW_JOB_ID}"
#       - "--acsengine-download-url=https://github.com/Azure/acs-engine/releases/download/v0.21.2/acs-engine-v0.21.2-linux-amd64.tar.gz"
#       - "--acsengine-creds=$AZURE_CREDENTIALS"
#       - "--acsengine-agentpoolcount=3"
#       - "--acsengine-public-key=$AZURE_SSH_PUBLIC_KEY_FILE"
#       - "--acsengine-winZipBuildScript=$WIN_BUILD"
#       - "--acsengine-location=eastus"
#       - "--acsengine-networkPlugin=kubenet"
#       - "--acsengine-orchestratorRelease=1.12"
#       - "--acsengine-win-binaries-url=https://acs-mirror.azureedge.net/wink8s/v1.12.0-beta.1-1int.zip"
#       - "--acsengine-hyperkube-url=k8s.gcr.io/hyperkube-amd64:v1.12.0-beta.1"
#        - "--test_args=--ginkgo.dryRun=false --ginkgo.noColor --ginkgo.focus=\\[Conformance\\]|\\[NodeConformance\\] --ginkgo.skip=\\[Serial\\]|\\[k8s.io\\].KubeletManagedEtcHosts.should.test.kubelet.managed./etc/hosts.file.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].PrivilegedPod.\\[NodeConformance\\].should.enable.privileged.commands|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].ConfigMap.should.be.consumable.from.pods.in.volume.with.mappings.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.as.non-root.with.defaultMode.and.fsGroup.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Secrets.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.Mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.as.non-root.with.defaultMode.and.fsGroup.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.defaultMode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.and.Item.Mode.set.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.be.consumable.from.pods.in.volume.with.mappings.as.non-root.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.set.DefaultMode.on.files.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Projected.should.set.mode.on.item.file.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Downward.API.volume.should.set.DefaultMode.on.files.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Downward.API.volume.should.set.mode.on.item.file.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0644,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0644,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0666,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0666,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0777,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(non-root,0777,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0644,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0644,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0666,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0666,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0777,default\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.should.support.\\(root,0777,tmpfs\\).\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.volume.on.default.medium.should.have.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].EmptyDir.volumes.volume.on.tmpfs.should.have.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].HostPath.should.give.a.volume.the.correct.mode.\\[NodeConformance\\].\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.configmap.pod.with.mountPath.of.existing.file.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.projected.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.secret.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.configmap.pod.\\[Conformance\\]|\\[sig-storage\\].Subpath.Atomic.writer.volumes.should.support.subpaths.with.downward.pod.\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.poststart.exec.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.poststart.http.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.prestop.exec.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Lifecycle.Hook.when.create.a.pod.with.lifecycle.hook.should.execute.prestop.http.hook.properly.\\[NodeConformance\\].\\[Conformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.from.private.registry.with.secret.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.image.from.docker.hub.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.be.able.to.pull.image.from.gcr.io.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.from.private.registry.without.secret.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.image.from.invalid.registry.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.running.a.container.with.a.new.image.should.not.be.able.to.pull.non-existing.image.from.gcr.io.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.as.empty.when.pod.succeeds.and.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.from.file.when.pod.succeeds.and.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.from.log.output.if.TerminationMessagePolicy.FallbackToLogOnError.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.if.TerminationMessagePath.is.set.as.non-root.user.and.at.a.non-default.path.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.report.termination.message.if.TerminationMessagePath.is.set.\\[NodeConformance\\]|\\[k8s.io\\].Container.Runtime.blackbox.test.when.starting.a.container.that.exits.should.run.with.the.expected.status.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.container.with.runAsUser.should.run.the.container.with.uid.0.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.container.with.runAsUser.should.run.the.container.with.uid.65534.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.privileged.should.run.the.container.as.unprivileged.when.false.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.readOnlyRootFilesystem.should.run.the.container.with.readonly.rootfs.when.readOnlyRootFilesystem=true.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.When.creating.a.pod.with.readOnlyRootFilesystem.should.run.the.container.with.writable.rootfs.when.readOnlyRootFilesystem=false.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.allow.privilege.escalation.when.not.explicitly.set.and.uid.!=.0.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.allow.privilege.escalation.when.true.\\[NodeConformance\\]|\\[k8s.io\\].Security.Context.when.creating.containers.with.AllowPrivilegeEscalation.should.not.allow.privilege.escalation.when.false.\\[NodeConformance\\]"
#       env:
#       - name: DOCKER_IN_DOCKER_ENABLED
#         value: "true"
#         # docker-in-docker needs privileged mode
#       volumeMounts:
#       - name: docker-graph
#         mountPath: /docker-graph
#       securityContext:
#         privileged: true
#     volumes:
#       - name: docker-graph
#         emptyDir: {}


tide:
  merge_method:
    e2e-win/test-infra: squash
    e2e-win/e2e-win-prow-deployment: squash
  queries:
  - repos:
    - e2e-win/test-infra
    - e2e-win/e2e-win-prow-deployment
    labels:
    - lgtm
    - approved
    missingLabels:
    - needs-ok-to-test
    - DO-NOT-MERGE
    - do-not-merge/work-in-progress
    - do-not-merge/hold
